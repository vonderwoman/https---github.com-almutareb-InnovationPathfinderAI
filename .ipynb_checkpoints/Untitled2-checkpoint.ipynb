{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0e4cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error: 401 - {\"error\":\"Access to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must be authenticated to access it.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI token is valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Error: 401 - {\"error\":\"Access to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must be authenticated to access it.\"}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "# Commented out as not required for this script\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# No longer needed for model access verification (public model)\n",
    "# HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Financial data (replace with your data source)\n",
    "assets = {\n",
    "    \"Assets 1\": 800,\n",
    "    \"Assets 2\": 1200,\n",
    "    \"Assets 3\": 4000,\n",
    "    \"Assets 4\": 1500,\n",
    "    \"Assets 5\": 9000,\n",
    "    \"Assets 6\": 3000\n",
    "}\n",
    "\n",
    "liabilities = {\n",
    "    \"Liabilities 1\": 2000,\n",
    "    \"Liabilities 2\": 1500,\n",
    "    \"Liabilities 3\": 3000,\n",
    "    \"Liabilities 4\": 300,\n",
    "    \"Liabilities 5\": 1800\n",
    "}\n",
    "\n",
    "income = {\n",
    "    \"Income 1\": 9000,\n",
    "    \"Income 2\": 1500,\n",
    "    \"Income 3\": 3000\n",
    "}\n",
    "\n",
    "expenses = {\n",
    "    \"Expense 1\": 500,\n",
    "    \"Expense 2\": 1000,\n",
    "    \"Expense 3\": 800,\n",
    "    \"Expense 4\": 1100,\n",
    "    \"Expense 5\": 1800,\n",
    "    \"Expense 6\": 1250,\n",
    "    \"Expense 7\": 1000,\n",
    "    \"Expense 8\": 3500\n",
    "}\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "\n",
    "def load_data(filename=None):\n",
    "    \"\"\"Loads financial data from a text file or the provided dictionaries.\n",
    "\n",
    "    Args:\n",
    "        filename (str, optional): Path to a text file containing financial data.\n",
    "            If None, the provided dictionaries (`assets`, `liabilities`, etc.)\n",
    "            are used. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of `Document` objects containing the financial data.\n",
    "    \"\"\"\n",
    "\n",
    "    if filename:\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        documents = []\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                documents.append(Document(line.strip()))\n",
    "    else:\n",
    "        documents = [\n",
    "            Document(str(data)) for data in [assets, liabilities, income, expenses]\n",
    "        ]\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = load_data()  # Load data (text file or dictionaries)\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_and_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "processed_documents = [\" \".join(clean_and_preprocess(doc.content)) for doc in documents]\n",
    "\n",
    "# Question answering model and tokenizer (public model)\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "def infer(question, history):\n",
    "    query = question\n",
    "    inputs = tokenizer(question, documents[0].content, return_tensors='pt')  # Assuming Document 0 is the relevant context\n",
    "    outputs = model(**inputs)\n",
    "    answer = tokenizer.convert_ids_to_tokens(outputs.answer_ids[0])\n",
    "    answer = ''.join(answer)\n",
    "    return {\"result\": answer}\n",
    "\n",
    "history = []\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, \"\"\n",
    "\n",
    "def bot(history):\n",
    "    print(\"History:\", history)\n",
    "    response = infer(history[-1][0], history)\n",
    "    print(\"Response:\", response)\n",
    "    history[-1][1] = response['result']\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column(elem_id=\"col-container\"):\n",
    "        chatbot = gr.Chatbot([], elem_id=\"chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42802d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
