{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0e4cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.48.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "History: [['what is France', None]]\n",
      "Response: France [SEP] assets content\n",
      "History: [['what is France', 'France [SEP] assets content'], ['what is Paris', None]]\n",
      "Response: assets content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# Initialize the question answering model and tokenizer\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Example documents - replace these with actual content\n",
    "assets = \"Assets content goes here.\"\n",
    "liabilities = \"Liabilities content goes here.\"\n",
    "income = \"Income content goes here.\"\n",
    "expenses = \"Expenses content goes here.\"\n",
    "\n",
    "# Preprocess documents\n",
    "def clean_and_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return \" \".join(tokens)  # Return as a single string\n",
    "\n",
    "processed_documents = [clean_and_preprocess(doc) for doc in [assets, liabilities, income, expenses]]\n",
    "\n",
    "def infer(question, documents):\n",
    "    inputs = tokenizer(question, documents[0], return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "    return answer\n",
    "\n",
    "def add_text(history, text):\n",
    "    history.append((text, None))\n",
    "    return history, \"\"\n",
    "\n",
    "def bot(history):\n",
    "    print(\"History:\", history)\n",
    "    response = infer(history[-1][0], processed_documents)\n",
    "    print(\"Response:\", response)\n",
    "    history[-1][1] = response\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column(elem_id=\"col-container\"):\n",
    "        chatbot = gr.Chatbot([], elem_id=\"chatbot\")\n",
    "        clear = gr.Button(\"Clear\")\n",
    "        with gr.Row():\n",
    "            question = gr.Textbox(label=\"Question\", placeholder=\"Type your question and hit Enter \")\n",
    "\n",
    "    question.submit(add_text, [chatbot, question], [chatbot, question], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42802d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
